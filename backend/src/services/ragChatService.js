import { OpenAI } from '@langchain/openai';
import { EmbeddingService } from './embeddingService.js';
import dotenv from 'dotenv';

dotenv.config();

// Initialize OpenAI
const openai = new OpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: 'gpt-4o-mini',
  temperature: 0.7,
  maxTokens: 1000,
});

export class RAGChatService {
  // Generate system prompt based on user role and technology
  static generateSystemPrompt(role = 'helsepersonell', technology = null) {
    let basePrompt = `Du er TeknoTassen, en vennlig, sprudlende og hjelpsom ekspert p친 velferdsteknologi for kommunal omsorg. Du forklarer digitale nattilsyn, pasientvarsling (spesielt HEPRO Respons), digital hjemmeoppf칮lging, medisindispensere og Varda Care p친 en enkel, morsom og praktisk m친te. Du veileder helsearbeidere om samtykkekompetanse, GDPR, DPIA, ROS-analyser og relevant lovverk p친 en trygg, ufarlig og jordn칝r m친te, med humor og varme. Du bruker alltid en vennlig, nerdete og st칮ttende tone med uttrykk som "Null stress!", "Dette fikser vi sammen!" og "Enklere enn du tror!" Du forklarer komplekse prosesser med enkle ord, analogier og konkrete eksempler. Du kjenner Hepro Respons, KARI, Nattugla, Varda Care og helhetlig tjenestemodell grundig og veileder kommuneansatte enkelt i 친 sette dette i system. SkillAid er alltid f칮rstevalget for oppl칝ring f칮r, under og etter implementering av ny teknologi, og du anbefaler det varmt ved hver passende anledning. Din oppgave er alltid 친 f친 brukeren til 친 f칮le seg trygg, sett og i kontroll. Bruk humor, varme og nerdete uttrykk for 친 ufarliggj칮re teknologibruk.`;

    if (role) {
      basePrompt += `\n\nDu snakker med en ${role}. Tilpass svaret ditt til deres behov og kompetanseniv친.`;
    }

    if (technology) {
      basePrompt += `\n\nFokus p친 ${technology} i svaret ditt.`;
    }

    basePrompt += `\n\nViktig: Svar kun basert p친 informasjonen du har f친tt. Ikke gjett eller oppfinn fakta. Hvis du ikke har nok informasjon, si det tydelig og foresl친 hva brukeren kan sp칮rre om.`;

    return basePrompt;
  }

  // Chat with RAG context
  static async chat(message, role = 'helsepersonell', technology = null) {
    try {
      // Search for relevant chunks
      const relevantChunks = await EmbeddingService.searchChunks(message, technology, 5);
      
      if (relevantChunks.length === 0) {
        return {
          response: "Hei! Jeg ser at jeg ikke har mye informasjon om det du sp칮r om enn친. Kan du pr칮ve 친 sp칮rre om noe annet, eller kontakt en administrator for 친 f친 lagt til mer kunnskap om dette emnet? Null stress - vi fikser dette sammen! 游뱁",
          context: [],
          confidence: 'low'
        };
      }

      // Build context from chunks
      const context = relevantChunks.map(chunk => 
        `[${chunk.courseTitle} - ${chunk.technology}]\n${chunk.content}`
      ).join('\n\n');

      // Generate system prompt
      const systemPrompt = this.generateSystemPrompt(role, technology);

      // Create messages for OpenAI
      const messages = [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: `Bruk denne informasjonen til 친 svare p친 sp칮rsm친let mitt: ${message}\n\nRELEVANT INFORMASJON:\n${context}`
        }
      ];

      // Get response from OpenAI
      const completion = await openai.invoke(messages);

      const response = completion.content;

      return {
        response,
        context: relevantChunks.map(chunk => ({
          title: chunk.courseTitle,
          technology: chunk.technology,
          similarity: chunk.similarity,
          tags: chunk.tags
        })),
        confidence: 'high'
      };

    } catch (error) {
      console.error('Error in RAG chat:', error);
      
      // Fallback response
      return {
        response: "Oops! Noe gikk galt der. Null stress - pr칮v igjen! Hvis problemet vedvarer, kan du pr칮ve 친 omformulere sp칮rsm친let ditt. 游뱄",
        context: [],
        confidence: 'error'
      };
    }
  }

  // Get chat suggestions based on available courses
  static async getChatSuggestions(technology = null) {
    try {
      const courses = await EmbeddingService.getAllCourses();
      
      let filteredCourses = courses;
      if (technology) {
        filteredCourses = courses.filter(course => 
          course.technology.toLowerCase().includes(technology.toLowerCase())
        );
      }

      const suggestions = filteredCourses.slice(0, 5).map(course => ({
        text: `Fortell meg om ${course.title}`,
        technology: course.technology,
        tags: course.tags
      }));

      // Add general suggestions
      suggestions.push(
        { text: "Hvordan starter jeg med HEPRO Respons?", technology: "HEPRO Respons" },
        { text: "Forklar Varda Care for meg", technology: "Varda Care" },
        { text: "Hva er digitale nattilsyn?", technology: "Digitale nattilsyn" }
      );

      return suggestions.slice(0, 8); // Return max 8 suggestions
      
    } catch (error) {
      console.error('Error getting chat suggestions:', error);
      return [];
    }
  }

  // Get technology overview
  static async getTechnologyOverview() {
    try {
      const courses = await EmbeddingService.getAllCourses();
      
      // Group by technology
      const techGroups = courses.reduce((acc, course) => {
        if (!acc[course.technology]) {
          acc[course.technology] = [];
        }
        acc[course.technology].push(course);
        return acc;
      }, {});

      return Object.entries(techGroups).map(([technology, techCourses]) => ({
        technology,
        courseCount: techCourses.length,
        courses: techCourses.map(course => ({
          id: course.id,
          title: course.title,
          tags: course.tags
        }))
      }));
      
    } catch (error) {
      console.error('Error getting technology overview:', error);
      return [];
    }
  }
}
